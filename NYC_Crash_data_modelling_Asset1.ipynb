{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vehicle crashes occur all over the world, with varying severity, traffic rules, vehicle characteristics, \n",
    "## driving behavior, weather etc., each of which play a significant role in the outcome of the crash.\n",
    "## While most of the data science applications for crash analysis have been only in advanced visualization, there is limited study of \n",
    "## developing advanced machine learning algorithms that can help predict future crashes and its severities based on several parameters.\n",
    "## The limited existing models are developed for much larger areas which may result in overfit/underfit issue.\n",
    "## Hence, 'One model fits all' is an outdated strategy and will not be beneficial in providing actionable insights to zone specific crashes which may have different parameters. \n",
    "\n",
    "## Through my project at the Data Incubator, I wish to develop an automated system which in return develops machine learning models \n",
    "## to predict future fatal or non fatal crashes for any chosen area. These models would be focussed towards very specific zones/areas/road corridors, which I term as micro-crash models.\n",
    "## The intention here is to develop custom models that are built solely on the data that is represented by that zone/area\n",
    "## rather than a much larger set. Having such area specific models through an automated system will be beneficial to a lot of state or federal\n",
    "## Department's of Transport who can have access to a tool that can deliver key actionable insights,\n",
    "## and help direct their crash preventive measures more effectively in future.\n",
    "## This can help direct their budget, initiatives, and efforts to specific locations that need the most attention.\n",
    "## Outcomes of such models can be imposing traffic regulations during peak crash hours, zones, restricitng certain category of vehicles etc.\n",
    "\n",
    "## Data availability:\n",
    "## A lot of Transportation agencies, City DOT's, Federal DOT's provide traffic and crash related open data that can be easily acquired\n",
    "## to develop this bigger idea. I wish to develop a full fledged application that can be responsive in real time and update the\n",
    "## models with live feed of additional data through pipelines whenever available. As of today, there is no such automated model development application in Transportation.\n",
    "\n",
    "# Asset 1:\n",
    "\n",
    "## 1. In an effort to emphasize on this idea, I have worked on the following project which aims to build a simple machine learning model to classify crashes with certain parameters into fatal or non-fatal.\n",
    "## 2. This model can be considered as just a small subset of the larger idea where micro-models can be developed for micro-zones/areas.\n",
    "## 3. By using crash data for NYC provided by City of New York at (https://data.cityofnewyork.us/Public-Safety/Motor-Vehicle-Collisions-Crashes/h9gi-nx95)\n",
    "## this project aims to identify the underlying relationship between different parameters such as time of day, month, factors contributing to crash,\n",
    "## vehicle type etc, and build a classifier to help identify if certain crash parameters in future can result into a fatal or non-fatal crash.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will import the needed libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(277620, 34)\n"
     ]
    }
   ],
   "source": [
    "# Read the data into a pandas data frame\n",
    "alldf = pd.read_csv(\"E:\\\\Data Science\\\\The_Data_Incubator\\\\Motor_Vehicle_Collisions_-_Crashes.csv\")\n",
    "print(alldf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CRASH DATE', 'CRASH TIME', 'BOROUGH', 'ZIP CODE', 'LATITUDE',\n",
       "       'LONGITUDE', 'LOCATION', 'ON STREET NAME', 'CROSS STREET NAME',\n",
       "       'OFF STREET NAME', 'NUMBER OF PERSONS INJURED',\n",
       "       'NUMBER OF PERSONS KILLED', 'NUMBER OF PEDESTRIANS INJURED',\n",
       "       'NUMBER OF PEDESTRIANS KILLED', 'NUMBER OF CYCLIST INJURED',\n",
       "       'NUMBER OF CYCLIST KILLED', 'NUMBER OF MOTORIST INJURED',\n",
       "       'NUMBER OF MOTORIST KILLED', 'CONTRIBUTING FACTOR VEHICLE 1',\n",
       "       'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
       "       'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5',\n",
       "       'COLLISION_ID', 'VEHICLE TYPE CODE 1', 'VEHICLE TYPE CODE 2',\n",
       "       'VEHICLE TYPE CODE 3', 'VEHICLE TYPE CODE 4', 'VEHICLE TYPE CODE 5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets take a look at the columns\n",
    "alldf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>NUMBER OF PERSONS INJURED</th>\n",
       "      <th>NUMBER OF PERSONS KILLED</th>\n",
       "      <th>NUMBER OF PEDESTRIANS INJURED</th>\n",
       "      <th>NUMBER OF PEDESTRIANS KILLED</th>\n",
       "      <th>NUMBER OF CYCLIST INJURED</th>\n",
       "      <th>NUMBER OF CYCLIST KILLED</th>\n",
       "      <th>NUMBER OF MOTORIST INJURED</th>\n",
       "      <th>NUMBER OF MOTORIST KILLED</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1.484782e+06</td>\n",
       "      <td>1.484782e+06</td>\n",
       "      <td>1.687725e+06</td>\n",
       "      <td>1.687711e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "      <td>1.687742e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>4.069174e+01</td>\n",
       "      <td>-7.387087e+01</td>\n",
       "      <td>2.653833e-01</td>\n",
       "      <td>1.193332e-03</td>\n",
       "      <td>5.096454e-02</td>\n",
       "      <td>6.422783e-04</td>\n",
       "      <td>2.129295e-02</td>\n",
       "      <td>8.650611e-05</td>\n",
       "      <td>1.929537e-01</td>\n",
       "      <td>4.633410e-04</td>\n",
       "      <td>2.847570e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.149829e+00</td>\n",
       "      <td>2.349715e+00</td>\n",
       "      <td>6.614285e-01</td>\n",
       "      <td>3.650929e-02</td>\n",
       "      <td>2.323322e-01</td>\n",
       "      <td>2.589028e-02</td>\n",
       "      <td>1.456992e-01</td>\n",
       "      <td>9.363957e-03</td>\n",
       "      <td>6.231047e-01</td>\n",
       "      <td>2.346951e-02</td>\n",
       "      <td>1.503889e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.013600e+02</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>4.066880e+01</td>\n",
       "      <td>-7.397664e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.817793e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>4.072246e+01</td>\n",
       "      <td>-7.392912e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.480008e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>4.076835e+01</td>\n",
       "      <td>-7.386671e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.902179e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>4.334444e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>8.000000e+00</td>\n",
       "      <td>2.700000e+01</td>\n",
       "      <td>6.000000e+00</td>\n",
       "      <td>4.000000e+00</td>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>4.300000e+01</td>\n",
       "      <td>5.000000e+00</td>\n",
       "      <td>4.324549e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LATITUDE     LONGITUDE  NUMBER OF PERSONS INJURED  \\\n",
       "count  1.484782e+06  1.484782e+06               1.687725e+06   \n",
       "mean   4.069174e+01 -7.387087e+01               2.653833e-01   \n",
       "std    1.149829e+00  2.349715e+00               6.614285e-01   \n",
       "min    0.000000e+00 -2.013600e+02               0.000000e+00   \n",
       "25%    4.066880e+01 -7.397664e+01               0.000000e+00   \n",
       "50%    4.072246e+01 -7.392912e+01               0.000000e+00   \n",
       "75%    4.076835e+01 -7.386671e+01               0.000000e+00   \n",
       "max    4.334444e+01  0.000000e+00               4.300000e+01   \n",
       "\n",
       "       NUMBER OF PERSONS KILLED  NUMBER OF PEDESTRIANS INJURED  \\\n",
       "count              1.687711e+06                   1.687742e+06   \n",
       "mean               1.193332e-03                   5.096454e-02   \n",
       "std                3.650929e-02                   2.323322e-01   \n",
       "min                0.000000e+00                   0.000000e+00   \n",
       "25%                0.000000e+00                   0.000000e+00   \n",
       "50%                0.000000e+00                   0.000000e+00   \n",
       "75%                0.000000e+00                   0.000000e+00   \n",
       "max                8.000000e+00                   2.700000e+01   \n",
       "\n",
       "       NUMBER OF PEDESTRIANS KILLED  NUMBER OF CYCLIST INJURED  \\\n",
       "count                  1.687742e+06               1.687742e+06   \n",
       "mean                   6.422783e-04               2.129295e-02   \n",
       "std                    2.589028e-02               1.456992e-01   \n",
       "min                    0.000000e+00               0.000000e+00   \n",
       "25%                    0.000000e+00               0.000000e+00   \n",
       "50%                    0.000000e+00               0.000000e+00   \n",
       "75%                    0.000000e+00               0.000000e+00   \n",
       "max                    6.000000e+00               4.000000e+00   \n",
       "\n",
       "       NUMBER OF CYCLIST KILLED  NUMBER OF MOTORIST INJURED  \\\n",
       "count              1.687742e+06                1.687742e+06   \n",
       "mean               8.650611e-05                1.929537e-01   \n",
       "std                9.363957e-03                6.231047e-01   \n",
       "min                0.000000e+00                0.000000e+00   \n",
       "25%                0.000000e+00                0.000000e+00   \n",
       "50%                0.000000e+00                0.000000e+00   \n",
       "75%                0.000000e+00                0.000000e+00   \n",
       "max                2.000000e+00                4.300000e+01   \n",
       "\n",
       "       NUMBER OF MOTORIST KILLED  COLLISION_ID  \n",
       "count               1.687742e+06  1.687742e+06  \n",
       "mean                4.633410e-04  2.847570e+06  \n",
       "std                 2.346951e-02  1.503889e+06  \n",
       "min                 0.000000e+00  2.200000e+01  \n",
       "25%                 0.000000e+00  2.817793e+06  \n",
       "50%                 0.000000e+00  3.480008e+06  \n",
       "75%                 0.000000e+00  3.902179e+06  \n",
       "max                 5.000000e+00  4.324549e+06  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Describe function provides a quick summary of key statistics of individual variable in the dataset\n",
    "alldf.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687742 entries, 0 to 1687741\n",
      "Data columns (total 29 columns):\n",
      "CRASH DATE                       1687742 non-null object\n",
      "CRASH TIME                       1687742 non-null object\n",
      "BOROUGH                          1172462 non-null object\n",
      "ZIP CODE                         1172256 non-null object\n",
      "LATITUDE                         1484782 non-null float64\n",
      "LONGITUDE                        1484782 non-null float64\n",
      "LOCATION                         1484782 non-null object\n",
      "ON STREET NAME                   1352781 non-null object\n",
      "CROSS STREET NAME                1108481 non-null object\n",
      "OFF STREET NAME                  242593 non-null object\n",
      "NUMBER OF PERSONS INJURED        1687725 non-null float64\n",
      "NUMBER OF PERSONS KILLED         1687711 non-null float64\n",
      "NUMBER OF PEDESTRIANS INJURED    1687742 non-null int64\n",
      "NUMBER OF PEDESTRIANS KILLED     1687742 non-null int64\n",
      "NUMBER OF CYCLIST INJURED        1687742 non-null int64\n",
      "NUMBER OF CYCLIST KILLED         1687742 non-null int64\n",
      "NUMBER OF MOTORIST INJURED       1687742 non-null int64\n",
      "NUMBER OF MOTORIST KILLED        1687742 non-null int64\n",
      "CONTRIBUTING FACTOR VEHICLE 1    1683163 non-null object\n",
      "CONTRIBUTING FACTOR VEHICLE 2    1456147 non-null object\n",
      "CONTRIBUTING FACTOR VEHICLE 3    110241 non-null object\n",
      "CONTRIBUTING FACTOR VEHICLE 4    23235 non-null object\n",
      "CONTRIBUTING FACTOR VEHICLE 5    5980 non-null object\n",
      "COLLISION_ID                     1687742 non-null int64\n",
      "VEHICLE TYPE CODE 1              1679286 non-null object\n",
      "VEHICLE TYPE CODE 2              1421797 non-null object\n",
      "VEHICLE TYPE CODE 3              107552 non-null object\n",
      "VEHICLE TYPE CODE 4              22624 non-null object\n",
      "VEHICLE TYPE CODE 5              5821 non-null object\n",
      "dtypes: float64(4), int64(7), object(18)\n",
      "memory usage: 373.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Lets take a look if we have null objects in the provided data\n",
    "alldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "## A micro-model can be applied to any user defined zone/area. It can be taken down to the level of individual streets provided we have enough detailed data\n",
    "## In our micro-modelling strategy, lets choose a zone/area based on Borough, and for a sample lets choose Manhattan\n",
    "df = alldf[alldf['BOROUGH'] == 'MANHATTAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRASH DATE</th>\n",
       "      <th>CRASH TIME</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>ZIP CODE</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "      <th>ON STREET NAME</th>\n",
       "      <th>CROSS STREET NAME</th>\n",
       "      <th>OFF STREET NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>COLLISION_ID</th>\n",
       "      <th>VEHICLE TYPE CODE 1</th>\n",
       "      <th>VEHICLE TYPE CODE 2</th>\n",
       "      <th>VEHICLE TYPE CODE 3</th>\n",
       "      <th>VEHICLE TYPE CODE 4</th>\n",
       "      <th>VEHICLE TYPE CODE 5</th>\n",
       "      <th>month</th>\n",
       "      <th>pd_datetime</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10/13/2016</td>\n",
       "      <td>11:23</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10011</td>\n",
       "      <td>40.744100</td>\n",
       "      <td>-73.995650</td>\n",
       "      <td>POINT (-73.99565 40.7441)</td>\n",
       "      <td>WEST 23 STREET</td>\n",
       "      <td>7 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3540699</td>\n",
       "      <td>Box Truck</td>\n",
       "      <td>Bulk Agriculture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>11/01/2016</td>\n",
       "      <td>22:10</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10013</td>\n",
       "      <td>40.722584</td>\n",
       "      <td>-74.006360</td>\n",
       "      <td>POINT (-74.00636 40.722584)</td>\n",
       "      <td>VARICK STREET</td>\n",
       "      <td>CANAL STREET</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3553200</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10/14/2016</td>\n",
       "      <td>23:15</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10034</td>\n",
       "      <td>40.869550</td>\n",
       "      <td>-73.915190</td>\n",
       "      <td>POINT (-73.91519 40.86955)</td>\n",
       "      <td>WEST 215 STREET</td>\n",
       "      <td>10 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3545177</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>11/03/2016</td>\n",
       "      <td>7:50</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10065</td>\n",
       "      <td>40.761486</td>\n",
       "      <td>-73.960620</td>\n",
       "      <td>POINT (-73.96062 40.761486)</td>\n",
       "      <td>EAST 62 STREET</td>\n",
       "      <td>1 AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3553289</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>Taxi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>10/27/2016</td>\n",
       "      <td>18:00</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>10012</td>\n",
       "      <td>40.724236</td>\n",
       "      <td>-73.997795</td>\n",
       "      <td>POINT (-73.997795 40.724236)</td>\n",
       "      <td>PRINCE STREET</td>\n",
       "      <td>BROADWAY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3551464</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>Sedan</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CRASH DATE CRASH TIME    BOROUGH ZIP CODE   LATITUDE  LONGITUDE  \\\n",
       "0  10/13/2016      11:23  MANHATTAN    10011  40.744100 -73.995650   \n",
       "1  11/01/2016      22:10  MANHATTAN    10013  40.722584 -74.006360   \n",
       "4  10/14/2016      23:15  MANHATTAN    10034  40.869550 -73.915190   \n",
       "5  11/03/2016       7:50  MANHATTAN    10065  40.761486 -73.960620   \n",
       "9  10/27/2016      18:00  MANHATTAN    10012  40.724236 -73.997795   \n",
       "\n",
       "                       LOCATION                    ON STREET NAME  \\\n",
       "0     POINT (-73.99565 40.7441)  WEST 23 STREET                     \n",
       "1   POINT (-74.00636 40.722584)  VARICK STREET                      \n",
       "4    POINT (-73.91519 40.86955)  WEST 215 STREET                    \n",
       "5   POINT (-73.96062 40.761486)  EAST 62 STREET                     \n",
       "9  POINT (-73.997795 40.724236)  PRINCE STREET                      \n",
       "\n",
       "  CROSS STREET NAME OFF STREET NAME  ...  COLLISION_ID  VEHICLE TYPE CODE 1  \\\n",
       "0          7 AVENUE             NaN  ...       3540699            Box Truck   \n",
       "1      CANAL STREET             NaN  ...       3553200                Sedan   \n",
       "4         10 AVENUE             NaN  ...       3545177                Sedan   \n",
       "5          1 AVENUE             NaN  ...       3553289                 Taxi   \n",
       "9          BROADWAY             NaN  ...       3551464                Sedan   \n",
       "\n",
       "   VEHICLE TYPE CODE 2  VEHICLE TYPE CODE 3  VEHICLE TYPE CODE 4  \\\n",
       "0     Bulk Agriculture                  NaN                  NaN   \n",
       "1                Sedan                  NaN                  NaN   \n",
       "4                Sedan                  NaN                  NaN   \n",
       "5                 Taxi                  NaN                  NaN   \n",
       "9                Sedan                  NaN                  NaN   \n",
       "\n",
       "   VEHICLE TYPE CODE 5  month  pd_datetime weekday hour  \n",
       "0                  NaN     10   2016-10-13       3   11  \n",
       "1                  NaN     11   2016-11-01       1   22  \n",
       "4                  NaN     10   2016-10-14       4   23  \n",
       "5                  NaN     11   2016-11-03       3    7  \n",
       "9                  NaN     10   2016-10-27       3   18  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We will try to model total fatalities that occur for a particular incident\n",
    "## In our modelling case, we would like to have strong predictors. We can obtain few indicators from the date column\n",
    "## We can split the date column and obtain crucial information such as month and weekday/weekend which may provide crucial insights\n",
    "df['month'] = pd.DatetimeIndex(df['CRASH DATE']).month\n",
    "df['pd_datetime'] = pd.to_datetime(df['CRASH DATE'])\n",
    "df['weekday'] = df['pd_datetime'].dt.dayofweek\n",
    "df['hour'] = pd.to_datetime(df['CRASH TIME']).dt.hour\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "## We can see that number of fatalities is a continuous random variable. Hence we will categorize that data into fatal(1) or non-fatal(0)\n",
    "df['output'] = df['NUMBER OF PERSONS KILLED'].apply(lambda x: 1 if x>0 else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "## Similarly, we will make other predictors as categorical.\n",
    "## Based on initial screening, will use our sample predictors as weekday, hour, month, 'CONTRIBUTING FACTOR VEHICLE 1', 'CONTRIBUTING FACTOR VEHICLE 2', 'CONTRIBUTING FACTOR VEHICLE 3',\n",
    "#'CONTRIBUTING FACTOR VEHICLE 4', 'CONTRIBUTING FACTOR VEHICLE 5',\n",
    "## We will convert the non-numeric data into numeric by usink a lebel-encoder\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le_factor = LabelEncoder()\n",
    "uniquelist_factor = df['CONTRIBUTING FACTOR VEHICLE 1'].unique().tolist() + df['CONTRIBUTING FACTOR VEHICLE 2'].unique().tolist() + df['CONTRIBUTING FACTOR VEHICLE 3'].unique().tolist() + df['CONTRIBUTING FACTOR VEHICLE 4'].unique().tolist() + df['CONTRIBUTING FACTOR VEHICLE 5'].unique().tolist()\n",
    "uniquelist_factor = list(dict.fromkeys(uniquelist_factor))\n",
    "le_factor.fit(uniquelist_factor)\n",
    "df['CONTRIBUTING FACTOR VEHICLE 1'] = le_factor.transform(df['CONTRIBUTING FACTOR VEHICLE 1'].astype(str))\n",
    "df['CONTRIBUTING FACTOR VEHICLE 2'] = le_factor.transform(df['CONTRIBUTING FACTOR VEHICLE 2'].astype(str))\n",
    "df['CONTRIBUTING FACTOR VEHICLE 3'] = le_factor.transform(df['CONTRIBUTING FACTOR VEHICLE 3'].astype(str))\n",
    "df['CONTRIBUTING FACTOR VEHICLE 4'] = le_factor.transform(df['CONTRIBUTING FACTOR VEHICLE 4'].astype(str))\n",
    "df['CONTRIBUTING FACTOR VEHICLE 5'] = le_factor.transform(df['CONTRIBUTING FACTOR VEHICLE 5'].astype(str))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    277393\n",
       "1       227\n",
       "Name: output, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## We want to check if we have equal proportion of fatal and non-fatal cases in the input dataset to avoid overfitting\n",
    "#sns.countplot(df['output'])\n",
    "df['output'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454, 34)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see that there are only a few fata cases as compared to non-fata cases.\n",
    "# Hence we will select the data to have equal values of both\n",
    "nonfatal_df = df[df['output'] == 0].sample(n=227)\n",
    "fatal_df = df[df['output'] == 1]\n",
    "combined = [nonfatal_df, fatal_df]\n",
    "final_output_df = pd.concat(combined)\n",
    "final_output_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(454, 8)\n",
      "(454,)\n"
     ]
    }
   ],
   "source": [
    "## Now we will define our input and output variables\n",
    "inputdf = final_output_df[['weekday','month','hour','CONTRIBUTING FACTOR VEHICLE 1','CONTRIBUTING FACTOR VEHICLE 2','CONTRIBUTING FACTOR VEHICLE 3','CONTRIBUTING FACTOR VEHICLE 4','CONTRIBUTING FACTOR VEHICLE 5']]\n",
    "outputdf  = final_output_df['output']\n",
    "print(inputdf.shape)\n",
    "print(outputdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We will now create training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainx, testx, trainy, testy = train_test_split(inputdf, outputdf, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shriks44\\Anaconda3_2019\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "## Now we will apply a simple logistic regression model to see if our model can classify the incidents correctly\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lm = LogisticRegression()\n",
    "model = lm.fit(trainx, trainy)\n",
    "predictions = model.predict(testx)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "print(accuracy_score(testy, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8245614035087719"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Trying with ADAboost classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics as sm\n",
    "\n",
    "abcmodel  = AdaBoostClassifier(n_estimators = 30)\n",
    "abcmodel.fit(trainx, trainy)\n",
    "predictions = abcmodel.predict(testx)\n",
    "sm.accuracy_score(testy, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "## As we can see here, the ADAboost classifier provides us with a better estimation accuracy as compared to a simple logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
